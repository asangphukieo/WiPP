#!/usr/bin/env python3

""" Snakefile for the first Pipeline part: Generation of Training Data
for manual classification

"""

import sys
import os
import re
# Add path to R and python libraries
base_dir = os.environ['WIPP_PATH']
R_lib_dir = os.path.join(base_dir, 'lib', 'R')
R_utils_file = os.path.join(R_lib_dir, 'utils.R')
py_lib_dir = os.path.join(base_dir, 'lib', 'python')
sys.path.append(py_lib_dir)

# Import Pipeline modules
import utils
import peak_visualization as pvis

# Load config file
configfile: 'config.yaml'

# proof check config data and get relevant data
algorithms, tr_data = utils.evaluate_training_config(config)
groupCorr_str = '' if not config['XCMS_params']['groupCorr'] else '--groupCorr'
out_dir = config['static_data'].get('output_dir', '')
if out_dir == '.':
    out_dir = ''

# Final output rule
rule all:
    input:
        expand(
            os.path.join(
                out_dir, '00_Training', '02_Visualization',
                '{algorithm}__{tr_file}__visualization_overview.csv'
            ),
            algorithm=algorithms,
            tr_file=tr_data['files']
        )
    wildcard_constraints:
        algorithm = '.*(?!__)',
        tr_file = '^(?!__).*(?!_visualization_overview.csv)'


# ------------------------------------------------------------------------------
# --------------------------------- CENTWAVE -----------------------------------
# ------------------------------------------------------------------------------

rule run_CW:
    input:
        os.path.join(
            config['static_data']['data_path'],
            config['training_data-general']['training_samples'],
            '{}.{}'.format('{tr_file}', tr_data['type'])
        )
    output:
        os.path.join(
            out_dir, '00_Training', '00_Peak_Picking', 'XCMS-CW',
            '{tr_file}__{parameter_CW}.csv'
        )
    conda:
        os.path.join('..', 'envs', 'R_env.yaml')
    params:
        cores = 2,
        groupCorr = groupCorr_str,
        R_dir = R_lib_dir,
        utils = R_utils_file,
        pwMin = lambda wildcards: \
            re.search('par0-(\d+\.\d+|\d+)', wildcards.parameter_CW).group(1),
        pwMax = lambda wildcards: \
            re.search('par1-(\d+\.\d+|\d+)', wildcards.parameter_CW).group(1),
        mzdiff = lambda wildcards: '--mzdiff {}'.format(
                    re.search('par2-{1}(-?\d+\.\d+|\d+)', wildcards.parameter_CW)\
                    .group(1).replace('-', 'm')
                ) if config['static_data'].get('high_resolution', False) else '',
        ppm = lambda wildcards: '--ppm {}'.format(
                re.search('par3-(\d+\.\d+|\d+)', wildcards.parameter_CW) \
                    .group(1)
            ) if config['static_data'].get('high_resolution', False) else ''
    shell:
        'Rscript {params.R_dir}/run_XCMS-CW.R {input} {output} '
        '--peakwidth {params.pwMin} {params.pwMax} {params.mzdiff} {params.ppm} '
        '--cores {params.cores} {params.groupCorr} --utils {params.utils}'
        


rule merge_XCMS_CW_training:
    input:
        expand(
            os.path.join(
                out_dir, '00_Training', '00_Peak_Picking', 'XCMS-CW',
                '{{tr_file}}__{parameter_CW}.csv'
            ), 
            parameter_CW=tr_data['params']['XCMS-CW'],
        )
    output:
        os.path.join(
            '00_Training', '01_Merging', 'XCMS-CW', '{tr_file}__merged.csv'
        )
    wildcard_constraints:
        XCMS_tr_file='.*(?!__)'
    params:
        peak_min_width = config['static_data']['peak_min_width'],
        peak_min_mz = config['static_data']['peak_min_mz'],
        tolerance = config['merging']['RT_tol']
    run:
        pvis.merge_detected_peaks(
            input, 'XCMS-CW', output[0],
            params.tolerance, params.peak_min_width, params.peak_min_mz
        )


# ------------------------------------------------------------------------------
# ------------------------------ MATCHEDFILTER ---------------------------------
# ------------------------------------------------------------------------------

rule run_MF:
    input:
        os.path.join(
            config['static_data']['data_path'],
            config['training_data-general']['training_samples'],
            '{}.{}'.format('{tr_file}', tr_data['type'])
        )
    output:
        os.path.join(
            out_dir, '00_Training', '00_Peak_Picking', 'XCMS-MF',
            '{tr_file}__{parameter_MF}.csv'
        )
    conda:
        os.path.join('..', 'envs', 'R_env.yaml')
    params:
        cores = 2,
        groupCorr = groupCorr_str,
        R_dir = R_lib_dir,
        utils = R_utils_file,
        fwhm = lambda wildcards: \
            re.search('par0-(\d+\.\d+|\d+)', wildcards.parameter_MF).group(1),
        sn = lambda wildcards: \
            re.search('par1-(\d+\.\d+|\d+)', wildcards.parameter_MF).group(1),
        mzdiff = lambda wildcards: '--mzdiff {}'.format(
                re.search('par2-{1}(-?\d+\.\d+|\d+)', wildcards.parameter_MF) \
                    .group(1).replace('-', 'm')
            ) if config['static_data'].get('high_resolution', False) else '',
        step = lambda wildcards: '--step {}'.format(
                re.search('par3-(\d+\.\d+|\d+)', wildcards.parameter_MF) \
                    .group(1)
            ) if config['static_data'].get('high_resolution', False) else '',
        steps = lambda wildcards: '--steps {}'.format(
                re.search('par4-(\d+\.\d+|\d+)', wildcards.parameter_MF) \
                    .group(1)
            ) if config['static_data'].get('high_resolution', False) else ''
    shell:
        'Rscript {params.R_dir}/run_XCMS-MF.R {input} {output} '
        '--fwhm {params.fwhm} --sn {params.sn} {params.mzdiff} {params.step} '
        '{params.steps} --cores {params.cores} {params.groupCorr} '
        '--utils {params.utils}'
        

        
rule merge_XCMS_MF_training:
    input:
        expand(
            os.path.join(
                out_dir, '00_Training', '00_Peak_Picking', 'XCMS-MF',
                '{{tr_file}}__{parameter_MF}.csv'
            ), 
            parameter_MF=tr_data['params']['XCMS-MF']
        )  
    output:
        os.path.join(
            out_dir, '00_Training', '01_Merging', 'XCMS-MF',
            '{tr_file}__merged.csv'
        )
    wildcard_constraints:
        XCMS_tr_file='.*(?!__)'
    params:
        peak_min_width = config['static_data']['peak_min_width'],
        peak_min_mz = config['static_data']['peak_min_mz'],
        tolerance = config['merging']['RT_tol']
    run:
        pvis.merge_detected_peaks(
            input, 'XCMS-MF', output[0],
            params.tolerance, params.peak_min_width, params.peak_min_mz
        )


# ------------------------------------------------------------------------------
# ------------------------------- ALL ALGORITHMS -------------------------------
# ------------------------------------------------------------------------------

rule visualize_training_data:
    input:
        os.path.join(
            out_dir, '00_Training', '01_Merging', '{algorithm}', 
            '{tr_file}__merged.csv'
        )
    output:
        os.path.join(
            out_dir, '00_Training', '02_Visualization',
            '{algorithm}__{tr_file}__visualization_overview.csv'
        )
    params:
        raw_data = config['static_data']['data_path'],
        train_dir = config['training_data-general']['training_samples'],
        file_type = tr_data['type'],
        plot_no = config['training_data-general']['plots_per_sample']
    threads:
        config['training_data-general']['plots_per_sample']
    run:
        pvis.visualize_peaks(
            input[0], params.raw_data, params.train_dir, params.file_type,
            params.plot_no, wildcards.algorithm, wildcards.tr_file, threads
        )
