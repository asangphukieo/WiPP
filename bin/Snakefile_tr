""" Snakefile for the first Pipeline part: the generation of Training Data
for manual classification

"""

import sys
import os
# Add path to R and python libraries
base_dir = os.path.split(os.path.split(os.getcwd())[0])[0]
R_lib_dir = os.path.join(base_dir, 'lib', 'R')
R_utils_file = os.path.join(R_lib_dir, 'utils.R')
py_lib_dir = os.path.join(base_dir, 'lib', 'python')
sys.path.append(py_lib_dir)
# Import Pipeline modules
import utils
import peak_visualization as pvis

# Load config file
configfile: 'config.yaml'

# proof check config data and get relevant data
algorithms, tr_data = utils.evaluate_training_config(config)
groupCorr_str = '' if not config['XCMS_params']['groupCorr'] else '--groupCorr'


# Final output rule
rule all:
    input:
        expand(
            '00_Training/02_Visualization/{algorithm}__{tr_file}__visualization_overview.csv',
            algorithm=algorithms,
            tr_file=tr_data['files']
        )
    wildcard_constraints:
        algorithm = '.*(?!__)',
        tr_file = '^(?!__).*(?!_visualization_overview.csv)'


# ------------------------------------------------------------------------------
# --------------------------------- CENTWAVE -----------------------------------
# ------------------------------------------------------------------------------

rule run_CW:
    input:
        os.path.join(
            config['static_data']['data_path'],
            config['training_data-general']['training_samples'],
            '{}.{}'.format('{tr_file}', tr_data['type'])
        )
    output:
        '00_Training/00_Peak_Picking/XCMS-CW/{tr_file}__{parameter_CW}.csv'
    params:
        cores = 2,
        groupCorr = groupCorr_str,
        R_dir = R_lib_dir,
        utils = R_utils_file
    run:
        # Low res params
        params.pwMin = re.search('par0-(\d+\.\d+|\d+)', wildcards.parameter_CW)\
            .group(1)
        params.pwMax = re.search('par1-(\d+\.\d+|\d+)', wildcards.parameter_CW) \
            .group(1)
        # HIgh res params
        if config['static_data'].get('high_resolution', False):
            params.mzdiff = '--mzdiff {}'.format(
                re.search('par2-{1}(-?\d+\.\d+|\d+)', wildcards.parameter_CW)\
                    .group(1).replace('-', 'm')
            )
            params.ppm = '--ppm {}'.format(
                re.search('par3-(\d+\.\d+|\d+)', wildcards.parameter_CW) \
                    .group(1)
            )
        else:
            params.mzdiff = ''
            params.ppm = ''

        shell(
            'Rscript {params.R_dir}/run_XCMS-CW.R {input} {output} '
            '--peakwidth {params.pwMin} {params.pwMax} '
            '{params.mzdiff} {params.ppm} '
            '--cores {params.cores} {params.groupCorr} --utils {params.utils}'
        )


rule merge_XCMS_CW_training:
    input:
        expand(
            '00_Training/00_Peak_Picking/XCMS-CW/{{tr_file}}__{parameter_CW}.csv',
            parameter_CW=tr_data['params']['XCMS-CW'],
        )  
    output:
        '00_Training/01_Merging/XCMS-CW/{tr_file}__merged.csv'
    wildcard_constraints:
        XCMS_tr_file='.*(?!__)'
    params:
        peak_min_width = config['static_data']['peak_min_width'],
        peak_min_mz = config['static_data']['peak_min_mz'],
        tolerance = config['merging']['RT_tol']
    run:
        pvis.merge_detected_peaks(
            input, 'XCMS-CW', output[0],
            params.tolerance, params.peak_min_width, params.peak_min_mz
        )


# ------------------------------------------------------------------------------
# ------------------------------ MATCHEDFILTER ---------------------------------
# ------------------------------------------------------------------------------

rule run_MF:
    input:
        os.path.join(
            config['static_data']['data_path'],
            config['training_data-general']['training_samples'],
            '{}.{}'.format('{tr_file}', tr_data['type'])
        )
    output:
        '00_Training/00_Peak_Picking/XCMS-MF/{tr_file}__{parameter_MF}.csv'
    params:
        cores = 2,
        groupCorr = groupCorr_str,
        R_dir = R_lib_dir,
        utils = R_utils_file
    run:
        # Low res params
        params.fwhm = re.search('par0-(\d+\.\d+|\d+)', wildcards.parameter_MF) \
            .group(1)
        params.sn = re.search('par1-(\d+\.\d+|\d+)', wildcards.parameter_MF) \
            .group(1)
        # Hgh res params
        if config['static_data'].get('high_resolution', False):
            params.mzdiff = '--mzdiff {}'.format(
                re.search('par2-{1}(-?\d+\.\d+|\d+)', wildcards.parameter_MF) \
                    .group(1).replace('-', 'm')
            )
            params.step = '--step {}'.format(
                re.search('par3-(\d+\.\d+|\d+)', wildcards.parameter_MF) \
                    .group(1)
            )
            params.steps = '--steps {}'.format(
                re.search('par4-(\d+\.\d+|\d+)', wildcards.parameter_MF) \
                    .group(1)
            )
        else:
            params.mzdiff = ''
            params.step = ''
            params.steps = ''

        shell(
            'Rscript {params.R_dir}/run_XCMS-MF.R {input} {output} '
            '--fwhm {params.fwhm} --sn {params.sn} '
            '{params.mzdiff} {params.step} {params.steps} '
            '--cores {params.cores} {params.groupCorr} --utils {params.utils}'
        )

        
rule merge_XCMS_MF_training:
    input:
        expand(
            '00_Training/00_Peak_Picking/XCMS-MF/{{tr_file}}__{parameter_MF}.csv',
            parameter_MF=tr_data['params']['XCMS-MF']
        )  
    output:
        '00_Training/01_Merging/XCMS-MF/{tr_file}__merged.csv'
    wildcard_constraints:
        XCMS_tr_file='.*(?!__)'
    params:
        peak_min_width = config['static_data']['peak_min_width'],
        peak_min_mz = config['static_data']['peak_min_mz'],
        tolerance = config['merging']['RT_tol']
    run:
        pvis.merge_detected_peaks(
            input, 'XCMS-MF', output[0],
            params.tolerance, params.peak_min_width, params.peak_min_mz
        )


# ------------------------------------------------------------------------------
# ------------------------------- ALL ALGORITHMS -------------------------------
# ------------------------------------------------------------------------------

rule visualize_training_data:
    input:
        '00_Training/01_Merging/{algorithm}/{tr_file}__merged.csv'
    output:
        '00_Training/02_Visualization/{algorithm}__{tr_file}__visualization_overview.csv'
    params:
        raw_data = config['static_data']['data_path'],
        train_dir = config['training_data-general']['training_samples'],
        file_type = tr_data['type'],
        plot_no = config['training_data-general']['plots_per_sample']
    threads:
        config['static_data']['cores']
    run:
        pvis.visualize_peaks(
            input[0], params.raw_data, params.train_dir, params.file_type,
            params.plot_no, wildcards.algorithm, wildcards.tr_file, threads
        )
